{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, markdown is cool. Anyway let's get started with some code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Token:\n",
    "    def __init__(self, code:int, lexeme:str):\n",
    "        self.code = code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    def __init__(self,input:str):\n",
    "        # input is the file in a single string\n",
    "        self.input = input\n",
    "        # token_map is a dictionary that maps the tokens to their codes\n",
    "        self.tokenList = {\n",
    "           1: Token(1, 'real_literal'),\n",
    "           2:Token(2, 'integer_literal'),\n",
    "           3: Token(3, 'bool_literal'),\n",
    "           4: Token(4, 'char_literal'),\n",
    "           5: Token(5, 'string_literal'), \n",
    "           6: Token(6, 'if'),\n",
    "           7: Token(7, 'else'),\n",
    "           8: Token(8, 'while'),\n",
    "           9: Token(9, 'for'),\n",
    "           10: Token(10, 'do'),\n",
    "           11: Token(11, 'var'),\n",
    "           12: Token(12, 'int'),\n",
    "           13: Token(13, 'bool'),\n",
    "           14: Token(14, 'char'),\n",
    "           15: Token(15, 'string'),\n",
    "           16: Token(16, 'real'),\n",
    "           17: Token(17, '+'),\n",
    "           18: Token(18, '-'),\n",
    "           19: Token(19, '*'),\n",
    "           20: Token(20, '/'),\n",
    "           21: Token(21, '%'),\n",
    "           22: Token(22, '='),\n",
    "           23: Token(23, '=='),\n",
    "           24: Token(24, '!=='),\n",
    "           25: Token(25, '<'),\n",
    "           26: Token(26, '>'),\n",
    "           27: Token(27, '<=='),\n",
    "           28: Token(28, '>=='),\n",
    "           29: Token(29, '&&'),\n",
    "           30: Token(30, '||'),\n",
    "           31: Token(31, '!'),\n",
    "           32: Token(32, '**'),\n",
    "           33: Token(33, '('),\n",
    "           34: Token(34, ')'),\n",
    "           35: Token(35, '{'),\n",
    "           36: Token(36, '}'),\n",
    "           37: Token(37, '~'),\n",
    "           38: Token(38, 'function'),\n",
    "           39: Token(39, 'id')\n",
    "        }\n",
    "        self.token_map = {'real_literal':1,\n",
    "                        'integer_literal':2,\n",
    "                        'bool_literal':3,\n",
    "                        'char_literal':4,\n",
    "                        'string_literal':5,\n",
    "                        'if':6,\n",
    "                        'else':7,\n",
    "                        'while':8,\n",
    "                        'for':9,\n",
    "                        'do':10,\n",
    "                        'var':11,\n",
    "                        'int':12,\n",
    "                        'bool':13,\n",
    "                        'char':14,\n",
    "                        'string':15,\n",
    "                        'real':16,\n",
    "                        '+':17,\n",
    "                        '-':18,\n",
    "                        '*':19,\n",
    "                        '/':20,\n",
    "                        '%':21,\n",
    "                        '=':22,\n",
    "                        '==':23,\n",
    "                        '!==':24,\n",
    "                        '<':25,\n",
    "                        '>':26,\n",
    "                        '<==':27,\n",
    "                        '>==':28,\n",
    "                        '&&':29,\n",
    "                        '||':30,\n",
    "                        '!':31,\n",
    "                        '**':32,\n",
    "                        '(':33,\n",
    "                        ')':34,\n",
    "                        '{':35,\n",
    "                        '}':36,\n",
    "                        '~':37,\n",
    "                        'function':38,\n",
    "                        'id':39,\n",
    "        }\n",
    "    \n",
    "    def find_tokens(self): \n",
    "        # finds all the tokens in a line\n",
    "        tokens = []\n",
    "        for i in self.input.split():\n",
    "            if i in self.token_map:\n",
    "                tokens.append(self.tokenList[self.token_map[i].key()])\n",
    "            else:\n",
    "                tokens.append(self.tokenList[self.token_map['id'].key()])\n",
    "        return tokens\n",
    "    \n",
    "            \n",
    "    def error():\n",
    "        # stops the program from running\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    \"\"\" Takes in a list of Token object in its constructor\n",
    "    Outputs a parse tree of called functions that would recognize the input is syntactically correct \"\"\"\n",
    "    def __init__(self,tokens:list(object)):\n",
    "        self.tokens = tokens\n",
    "        if self.empty():\n",
    "            print(\"Empty file\")\n",
    "        else:\n",
    "            self.program()\n",
    "    def program(self):\n",
    "        #<program> --> <stmt>\n",
    "        self.stmt() \n",
    "    def stmt(self):\n",
    "        #<stmt> --> <block> | <if_stmt> | <assignment> |<empty>\n",
    "        if self.tokens[0].code == 35:\n",
    "            self.block()\n",
    "        elif self.tokens[0].code == 6:\n",
    "            self.if_stmt()\n",
    "        elif self.tokens[0].code == 11:\n",
    "            self.assignment()\n",
    "        elif self.tokens[0].code == 38:\n",
    "            self.functions()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "\n",
    "    def empty(self):\n",
    "        #<empty> --> ''\n",
    "        if len(self.tokens) == 0:\n",
    "            return True\n",
    "    \n",
    "    def block(self):\n",
    "        #<block> --> `{`{<stmt>}`}`\n",
    "        if self.tokens[0].code == 35:\n",
    "            self.tokens.pop(0)\n",
    "            while self.tokens[0].code != 36:\n",
    "                self.stmt()\n",
    "            self.tokens.pop(0)\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    \n",
    "    def loop(self):\n",
    "        # <loop> --> <while_loop> | <do_while> | <for_loop>\n",
    "        if self.tokens[0].code == 8:\n",
    "            self.while_loop()\n",
    "        elif self.tokens[0].code == 10:\n",
    "            self.do_while()\n",
    "        elif self.tokens[0].code == 9:\n",
    "            self.for_loop()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    \n",
    "    def if_stmt(self):\n",
    "        # <if_stmt>   -->  `if``(`<bool_stmt> `)`<stmt>[`else ` <stmt>]\n",
    "        if self.tokens[0].code == 6:\n",
    "            self.tokens.pop(0)\n",
    "            if self.tokens[0].code == 33:\n",
    "                self.tokens.pop(0)\n",
    "                self.bool_stmt()\n",
    "                if self.tokens[0].code == 34:\n",
    "                    self.tokens.pop(0)\n",
    "                    self.stmt()\n",
    "                    if self.tokens[0].code == 7:\n",
    "                        self.tokens.pop(0)\n",
    "                        self.stmt()\n",
    "                else:\n",
    "                    Lexer.error()\n",
    "            else:\n",
    "                Lexer.error()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    \n",
    "    def do_while(self):\n",
    "        # <do_while> --> `do` <block> <while_loop>\n",
    "        if self.tokens[0].code == 10:\n",
    "            self.tokens.pop(0)\n",
    "            self.block()\n",
    "            self.while_loop()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    \n",
    "    def while_loop(self):\n",
    "        # <while_loop> -->  `while``(`<bool_stmt>`)`<stmt>\n",
    "        if self.tokens[0].code == 8:\n",
    "            self.tokens.pop(0)\n",
    "            if self.tokens[0].code == 33:\n",
    "                self.tokens.pop(0)\n",
    "                self.bool_stmt()\n",
    "                if self.tokens[0].code == 34:\n",
    "                    self.tokens.pop(0)\n",
    "                    self.stmt()\n",
    "                else:\n",
    "                    Lexer.error()\n",
    "            else:\n",
    "                Lexer.error()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    \n",
    "    def for_loop(self):\n",
    "        # <for_loop> --> `for``(`<bool_stmt>`)`<block>\n",
    "        if self.tokens[0].code == 9:\n",
    "            self.tokens.pop(0)\n",
    "            if self.tokens[0].code == 33:\n",
    "                self.tokens.pop(0)\n",
    "                self.bool_stmt()\n",
    "                if self.tokens[0].code == 34:\n",
    "                    self.tokens.pop(0)\n",
    "                    self.block()\n",
    "                else:\n",
    "                    Lexer.error()\n",
    "            else:\n",
    "                Lexer.error()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    # <assignment> --> `var` <id> `=` <expr>\n",
    "    def assignment(self):\n",
    "        if self.tokens[0].code == 11:\n",
    "            self.tokens.pop(0)\n",
    "            if self.tokens[0].code == 39:\n",
    "                self.tokens.pop(0)\n",
    "                if self.tokens[0].code == 22:\n",
    "                    self.tokens.pop(0)\n",
    "                    self.expr()\n",
    "                else:\n",
    "                    Lexer.error()\n",
    "            else:\n",
    "                Lexer.error()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    \n",
    "    def functions(self):\n",
    "        # <functions> -- > `function` <id> `(` <id> `)` <block>\n",
    "        if self.tokens[0].code == 38:\n",
    "            self.tokens.pop(0)\n",
    "            if self.tokens[0].code == 39:\n",
    "                self.tokens.pop(0)\n",
    "                if self.tokens[0].code == 33:\n",
    "                    self.tokens.pop(0)\n",
    "                    if self.tokens[0].code == 39:\n",
    "                        self.tokens.pop(0)\n",
    "                        if self.tokens[0].code == 34:\n",
    "                            self.tokens.pop(0)\n",
    "                            self.block()\n",
    "                        else:\n",
    "                            Lexer.error()\n",
    "                    else:\n",
    "                        Lexer.error()\n",
    "                else:\n",
    "                    Lexer.error()\n",
    "            else:\n",
    "                Lexer.error()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    # <expr> --> <term> {(`+`|`-`)<term>}\n",
    "    def expr(self):\n",
    "        if self.tokens[0].code == 39:\n",
    "            self.term()\n",
    "            while self.tokens[0].code == 21 or self.tokens[0].code == 20:\n",
    "                self.tokens.pop(0)\n",
    "                self.term()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    # <term> --> <val>{(`*`|`/`|`%`|`\\*\\*`)<val>}\n",
    "    def term(self):\n",
    "        if self.tokens[0].code == 39 or self.tokens[0].code == 40 or self.tokens[0].code == 41 or self.tokens[0].code == 42:\n",
    "            self.val()\n",
    "            while self.tokens[0].code == 23 or self.tokens[0].code == 24 or self.tokens[0].code == 25 or self.tokens[0].code == 26:\n",
    "                self.tokens.pop(0)\n",
    "                self.val()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    # <val> --> <id> | <real_literal> | <integer_literal> | <bool_literal> | <char_literal> | <string_literal> | `(` <expr> `)`\n",
    "    def val(self):\n",
    "        if self.tokens[0].code == 39:\n",
    "            self.tokens.pop(0)\n",
    "        elif self.tokens[0].code == 40:\n",
    "            self.tokens.pop(0)\n",
    "        elif self.tokens[0].code == 41:\n",
    "            self.tokens.pop(0)\n",
    "        elif self.tokens[0].code == 42:\n",
    "            self.tokens.pop(0)\n",
    "        elif self.tokens[0].code == 43:\n",
    "            self.tokens.pop(0)\n",
    "        elif self.tokens[0].code == 44:\n",
    "            self.tokens.pop(0)\n",
    "        elif self.tokens[0].code == 33:\n",
    "            self.tokens.pop(0)\n",
    "            self.expr()\n",
    "            if self.tokens[0].code == 34:\n",
    "                self.tokens.pop(0)\n",
    "            else:\n",
    "                Lexer.error()\n",
    "        else:\n",
    "            Lexer.error()\n",
    "    # <bool_stmt> --> `True` | `False` | <expr> (`==`|`!==`|`<`|`>`|`<==`|`>==`) <expr> \n",
    "    def bool_stmt(self):\n",
    "        if self.tokens[0].code == 42:\n",
    "            self.tokens.pop(0)\n",
    "        elif self.tokens[0].code == 41:\n",
    "            self.tokens.pop(0)\n",
    "        else:\n",
    "            self.expr()\n",
    "            if self.tokens[0].code == 27 or self.tokens[0].code == 28 or self.tokens[0].code == 29 or self.tokens[0].code == 30 or self.tokens[0].code == 31 or self.tokens[0].code == 32:\n",
    "                self.tokens.pop(0)\n",
    "                self.expr()\n",
    "            else:\n",
    "                Lexer.error()\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Semantics:\n",
    "    def __init__(self, tokens):\n",
    "        self.tokens = tokens\n",
    "        self.current_token = None\n",
    "        self.next_token = None\n",
    "        self.current_token_index = 0\n",
    "        self.next_token_index = 1\n",
    "        self.check_semantics()\n",
    "\n",
    "        while(self.current_token_index < len(self.tokens)):  \n",
    "            self.current_token = self.tokens[self.current_token_index]\n",
    "            self.next_token = self.tokens[self.next_token_index]\n",
    "            self.current_token_index += 1\n",
    "            self.next_token_index += 1\n",
    "            self.check_semantics()\n",
    "    \n",
    "    def check_semantics(self):\n",
    "        if self.current_token.code == 39:\n",
    "            if self.next_token.code == 22:\n",
    "                self.next_token = self.tokens[self.next_token_index + 1]\n",
    "                if self.next_token.code == 39:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "                elif self.next_token.code == 40:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "                elif self.next_token.code == 41:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "                elif self.next_token.code == 42:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "                elif self.next_token.code == 43:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "                elif self.next_token.code == 44:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "                elif self.next_token.code == 33:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "                else:\n",
    "                    print(\"Variable \" + self.current_token.lexeme + \" has been assigned the value \" + self.next_token.lexeme)\n",
    "            else:\n",
    "                print(\"Variable \" + self.current_token.lexeme + \" has been declared\")\n",
    "        else:\n",
    "            pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Compiler:\n",
    "    def __init__(self, file:str):\n",
    "        self.file = file\n",
    "        text_file = open(file, \"r\")\n",
    "\n",
    "        input = text_file.read()\n",
    "        lex = Lexer(input)\n",
    "        tokens = lex.find_tokens()\n",
    "        print(tokens)\n",
    "        parser = Parser(tokens)\n",
    "        parser.program()\n",
    "        text_file.close\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7fe7439c5735edab5b1c40c746e0470d90449e584972202a3f74838ceba4319"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
